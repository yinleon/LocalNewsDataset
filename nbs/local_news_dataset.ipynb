{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Local News Dataset\n",
    "View this on [Github]() | [NbViewer]() |  [Binder]()<br>\n",
    "by [Leon Yin]()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "1. [Introduction](#intro)\n",
    "2. [Tech Specs](#specs)\n",
    "3. [Using the Dataset](#use)\n",
    "4. [Data Sheet](#datasheet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Introduction <a name='intro'></a>\n",
    "2018 has shown us that any medium with an audience can be a vehicle for political propoganda. We saw local news outlets used as a sounding board to decry mainstream media outlets as \"[fake news](https://www.youtube.com/watch?v=khbihkeOISc)\", we also saw Russian trolls masquarade as local news outlets to [build trust](https://www.npr.org/2018/07/12/628085238/russian-influence-campaign-sought-to-exploit-americans-trust-in-local-news) as sleeper accounts on Twitter. \n",
    "\n",
    "Understanding \"fake news\" -- and the media (manipulation) ecosystem at large, has as much to do with Alex Jones and CNN, as your local broadcasting station. To help put the pieces of this ecosystem into context, we can refer to a 2016 [Pew Study](http://www.journalism.org/2016/07/07/trust-and-accuracy/) on Trust and Accuracy of the Modern Media Consumer-- 86% of survey respondants had \"a lot\" or \"some\" confidence in local news. This was more than national media outlets, social media, and family and friends. \n",
    "\n",
    "<a href=\"http://www.journalism.org/2016/07/07/the-modern-news-consumer/pj_2016-07-07_modern-news-consumer_2-01/\"><img width=\"420\" height=\"399\" src=\"http://assets.pewresearch.org/wp-content/uploads/sites/13/2016/07/PJ_2016.07.07_Modern-News-Consumer_2-01.png\" class=\"attachment-large size-large\" alt=\"Few have a lot of confidence in information from professional news outlets or friends and family, though majorities show at least some trust in both, but social media garners less trust than either\" /></a>\n",
    "\n",
    "Social media is the least trustworthy news source according to the 4.6K respondants of the Pew study. Mind you, this study was published before the 2016 US Presidential Election and social media platforms were not under the same scrutiny as they are today. \n",
    "\n",
    "The biggest finding of the study: very few have \"a lot\" of trust in information from professional news outlets. Is this because of so called, \"Fake news\"-- blurring the line between reputible and problematic information? Political Scientist Andy Guess has shown that senior citizens who are less tech-savvy are more suspectiple to spread links containing junk news on Facebook. Yet mis and dis-information is more than the [junk news](https://www.buzzfeednews.com/article/craigsilverman/viral-fake-election-news-outperformed-real-news-on-facebook) sites Craig Silverman analyzed when he first coined \"Fake news\" in 2016. \n",
    "\n",
    "<img src='../media/fake_news.png' alt='Few have a lot of confidence in information from professional news outlets or friends and family, though majorities show at least some trust in both, but social media garners less trust than either'/> </img>\n",
    "\n",
    "The media historian Caroline Jack has helped introduce a [lexicon](https://datasociety.net/output/lexicon-of-lies/) to describe content formerly known as \"fake news,\" with more nuance. She calls this umbrella of disceptive content problematic information.\n",
    "The social media scholar Alice Marwick [builds off this lexicon and observes that](https://www.georgetownlawtechreview.org/why-do-people-share-fake-news-a-sociotechnical-model-of-media-effects/GLTR-07-2018/) problematic information spreads not only through junk news headlines, but also through memes, videos and podcats. What other mediums are we overlooking? As a hint, we can listen to Marwick and other researchers such as ethnographer [Francesca Tripoldi](https://datasociety.net/output/searching-for-alternative-facts/), who observe that problematic information is deeply connected to one's self-presentation and the reinforcement of group identity. So where does local news fit into this equation?\n",
    "\n",
    "Local news -- viewed as a trustworthy news source, is not well-studied in its role in the current media and information landscape. To better understand that role, I put together the `Local News Dataset` in hopes that it will accelerate research of local news across the web.\n",
    "\n",
    "## About the Data Set\n",
    "This dataset is a machine-readible directory of state-level newspapers, tv stations and magazines. In addition to basic information such as the name of the outlet and state it is located in, all available information regarding web presence, social media (twitter, youtube, facebook) and their owners is scraped, too.\n",
    "\n",
    "The sources of this dataset are [usnpl.com](www.usnpl.com)-- newspapers and magazines by state, [stationindex.com](www.stationindex.com) -- tv stations by state and by owner, and homepages of the media corporations Meridith, Sinclair, Nexstar, Tribune and Hearst.\n",
    "\n",
    "This dataset was inspired by Propublica's [Congress API](https://projects.propublica.org/api-docs/congress-api/). I hope that this dataset will serve a similar purpose as a starting point for research and applications, as well as a bridge linking together datasets from social media, news articles and online communities.\n",
    "\n",
    "While you use this dataset, if you see irregularities, questionable entries, or missing outlets please submit an issue on Github or contact me on Twitter. I'd love to hear about how you use this dataset! \n",
    "\n",
    "Happy hunting xo\n",
    "\n",
    "## Acknowledgements\n",
    "The recent NPR report cited above played a major role in framing Local News. I'd also like to acknowledge the work of usnpl.com and stationindex.com for compiling lists of local media outlets.\n",
    "\n",
    "\n",
    "## Citation\n",
    "If this dataset plays a role in your research please cite it as:\n",
    "```\n",
    "@misc{Yin:2018\n",
    "author = {Leon Yin},\n",
    "title = {Local News Dataset},\n",
    "year = {2018}\n",
    "howpublished= {\\url{TODO}} \n",
    "\n",
    "```\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Data Specs <a name='specs'></a>\n",
    "The Local News Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated 2018-08-02 17:40:21.928761\n",
      "By Leon\n",
      "Using Python 3.6.5\n",
      "On Linux-3.10.0-514.10.2.el7.x86_64-x86_64-with-centos-7.3.1611-Core\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "## Inventory\n",
       "These are the files in the `../data/` folder.\n",
       "\n",
       "### Outputs\n",
       "- [local_news_dataset_2018.csv](#local_news_dataset_2018)\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Intermediates \n",
       " - [sinclair.tsv](#filename)\n",
       " - [meredith.tsv](#filename)\n",
       " - [nexstar.tsv](#filename)\n",
       " - [hearst.tsv](#filename)\n",
       " - [tribune.tsv](#filename)\n",
       " - [station_index.tsv](#filename)\n",
       " - [usnpl.tsv](#filename)\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<hr>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "## <a name='sinclair'>sinclair.tsv</a>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "An intermediate file of news outlets owned by Sinclair scraped from their website"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Read the raw file from this URL: \n",
       " `TODO`\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "See the code used to make this dataset: \n",
       " `TODO`\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "#### What Does the Data Look Like?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Sample of `../data/sinclair.tsv` (N = 611)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>geo</th>\n",
       "      <th>network</th>\n",
       "      <th>state</th>\n",
       "      <th>station</th>\n",
       "      <th>website</th>\n",
       "      <th>broadcaster</th>\n",
       "      <th>source</th>\n",
       "      <th>collection_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Norfolk</td>\n",
       "      <td>NorfolkPortsmouthNewport News, VA</td>\n",
       "      <td>tbd</td>\n",
       "      <td>VA</td>\n",
       "      <td>WTVZ-4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sinclair</td>\n",
       "      <td>sbgi.net</td>\n",
       "      <td>2018-08-02 14:55:24.612585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Eastern</td>\n",
       "      <td>Greenville-N.Bern-Washngtn</td>\n",
       "      <td>movies!</td>\n",
       "      <td>NC</td>\n",
       "      <td>WCTI-3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sinclair</td>\n",
       "      <td>sbgi.net</td>\n",
       "      <td>2018-08-02 14:55:24.612585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fresno</td>\n",
       "      <td>FresnoVisalia, CA</td>\n",
       "      <td>comet</td>\n",
       "      <td>CA</td>\n",
       "      <td>KMPH-3</td>\n",
       "      <td>http://www.comettv.com/</td>\n",
       "      <td>Sinclair</td>\n",
       "      <td>sbgi.net</td>\n",
       "      <td>2018-08-02 14:55:24.612585</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      city                                geo  network state station  \\\n",
       "0  Norfolk  NorfolkPortsmouthNewport News, VA      tbd    VA  WTVZ-4   \n",
       "1  Eastern         Greenville-N.Bern-Washngtn  movies!    NC  WCTI-3   \n",
       "2   Fresno                  FresnoVisalia, CA    comet    CA  KMPH-3   \n",
       "\n",
       "                   website broadcaster    source             collection_date  \n",
       "0                      NaN    Sinclair  sbgi.net  2018-08-02 14:55:24.612585  \n",
       "1                      NaN    Sinclair  sbgi.net  2018-08-02 14:55:24.612585  \n",
       "2  http://www.comettv.com/    Sinclair  sbgi.net  2018-08-02 14:55:24.612585  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "#### What do the columns mean?\n",
       "| Column Name | Description | N Unique Values |\n",
       "| --- | --- | --- |\n",
       "| `city` | The name of the city that the TV station broadcasts from. | 85 |\n",
       "| `geo` | The raw geolocation field from the website. We parse this field to get `city` and `state` | 89 |\n",
       "| `network` | The franchise or brand name that the station belongs to IE Fox | 28 |\n",
       "| `state` | The two letter state abbreviation of the media outlet. | 35 |\n",
       "| `station` | The name of the TV station IE (\"KRIV\"). If anyone knows the origin of this naming convention, I would love to know! | 611 |\n",
       "| `website` | The website of the media outlet exactly as we found it online. | 152 |\n",
       "| `broadcaster` | The corporate owner of the station. | 1 |\n",
       "| `source` | Where was this record scraped from? | 1 |\n",
       "| `collection_date` | when was this record collected? | 1 |\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "[Top of Data Sheet](#datasheet)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "## <a name='meredith'>meredith.tsv</a>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "An intermediate file of news outlets owned by Meredith scraped from their website"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Read the raw file from this URL: \n",
       " `TODO`\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "See the code used to make this dataset: \n",
       " `TODO`\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "#### What Does the Data Look Like?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Sample of `../data/meredith.tsv` (N = 16)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>facebook</th>\n",
       "      <th>google</th>\n",
       "      <th>network</th>\n",
       "      <th>state</th>\n",
       "      <th>station</th>\n",
       "      <th>twitter</th>\n",
       "      <th>website</th>\n",
       "      <th>broadcaster</th>\n",
       "      <th>source</th>\n",
       "      <th>collection_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Phoenix</td>\n",
       "      <td>https://www.facebook.com/CBS5AZ</td>\n",
       "      <td>https://plus.google.com/+cbs5az/posts</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AZ</td>\n",
       "      <td>KPHO</td>\n",
       "      <td>https://twitter.com/CBS5AZ</td>\n",
       "      <td>http://www.kpho.com/</td>\n",
       "      <td>Meredith</td>\n",
       "      <td>meridith.com</td>\n",
       "      <td>2018-08-02 14:55:24.612585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nashville</td>\n",
       "      <td>https://www.facebook.com/WSMVTV</td>\n",
       "      <td>https://plus.google.com/117143042785436999262/...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TN</td>\n",
       "      <td>WSMV</td>\n",
       "      <td>https://twitter.com/WSMV</td>\n",
       "      <td>http://www.wsmv.com</td>\n",
       "      <td>Meredith</td>\n",
       "      <td>meridith.com</td>\n",
       "      <td>2018-08-02 14:55:24.612585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Springfield</td>\n",
       "      <td>https://www.facebook.com/westernmassnews</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MA</td>\n",
       "      <td>Western Mass News</td>\n",
       "      <td>https://twitter.com/WMASSNEWS</td>\n",
       "      <td>http://www.westernmassnews.com</td>\n",
       "      <td>Meredith</td>\n",
       "      <td>meridith.com</td>\n",
       "      <td>2018-08-02 14:55:24.612585</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          city                                  facebook  \\\n",
       "0      Phoenix           https://www.facebook.com/CBS5AZ   \n",
       "1    Nashville           https://www.facebook.com/WSMVTV   \n",
       "2  Springfield  https://www.facebook.com/westernmassnews   \n",
       "\n",
       "                                              google  network state  \\\n",
       "0              https://plus.google.com/+cbs5az/posts      NaN    AZ   \n",
       "1  https://plus.google.com/117143042785436999262/...      NaN    TN   \n",
       "2                                                NaN      NaN    MA   \n",
       "\n",
       "             station                        twitter  \\\n",
       "0               KPHO     https://twitter.com/CBS5AZ   \n",
       "1               WSMV       https://twitter.com/WSMV   \n",
       "2  Western Mass News  https://twitter.com/WMASSNEWS   \n",
       "\n",
       "                          website broadcaster        source  \\\n",
       "0            http://www.kpho.com/    Meredith  meridith.com   \n",
       "1             http://www.wsmv.com    Meredith  meridith.com   \n",
       "2  http://www.westernmassnews.com    Meredith  meridith.com   \n",
       "\n",
       "              collection_date  \n",
       "0  2018-08-02 14:55:24.612585  \n",
       "1  2018-08-02 14:55:24.612585  \n",
       "2  2018-08-02 14:55:24.612585  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "#### What do the columns mean?\n",
       "| Column Name | Description | N Unique Values |\n",
       "| --- | --- | --- |\n",
       "| `city` | The name of the city that the TV station broadcasts from. | 12 |\n",
       "| `facebook` | The URL to the media outlet's Facebook presence. | 14 |\n",
       "| `google` | The URL to the media outlet's Google Plus presence. | 13 |\n",
       "| `network` | The franchise or brand name that the station belongs to IE Fox | 1 |\n",
       "| `state` | The two letter state abbreviation of the media outlet. | 11 |\n",
       "| `station` | The name of the TV station IE (\"KRIV\"). If anyone knows the origin of this naming convention, I would love to know! | 16 |\n",
       "| `twitter` | The URL to the Twitter screen name of the news outlet. | 14 |\n",
       "| `website` | The website of the media outlet exactly as we found it online. | 16 |\n",
       "| `broadcaster` | The corporate owner of the station. | 1 |\n",
       "| `source` | Where was this record scraped from? | 1 |\n",
       "| `collection_date` | when was this record collected? | 1 |\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "[Top of Data Sheet](#datasheet)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "## <a name='nexstar'>nexstar.tsv</a>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "An intermediate file of news outlets owned by Nexstar scraped from their website"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Read the raw file from this URL: \n",
       " `TODO`\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "See the code used to make this dataset: \n",
       " `TODO`\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "#### What Does the Data Look Like?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Sample of `../data/nexstar.tsv` (N = 100)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station</th>\n",
       "      <th>website</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>broadcaster</th>\n",
       "      <th>source</th>\n",
       "      <th>collection_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WHBF KGCW KLJB</td>\n",
       "      <td>ourquadcities.com</td>\n",
       "      <td>Davenport, IA - Rock Island / Moline</td>\n",
       "      <td>IL</td>\n",
       "      <td>Nexstar</td>\n",
       "      <td>nexstar.tv</td>\n",
       "      <td>2018-08-02 14:55:24.612585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KTVX KUCW</td>\n",
       "      <td>good4utah.com</td>\n",
       "      <td>Salt Lake City</td>\n",
       "      <td>UT</td>\n",
       "      <td>Nexstar</td>\n",
       "      <td>nexstar.tv</td>\n",
       "      <td>2018-08-02 14:55:24.612585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WVNS</td>\n",
       "      <td>wvnstv.com</td>\n",
       "      <td>Bluefield / Beckley</td>\n",
       "      <td>WV</td>\n",
       "      <td>Nexstar</td>\n",
       "      <td>nexstar.tv</td>\n",
       "      <td>2018-08-02 14:55:24.612585</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          station            website                                  city  \\\n",
       "0  WHBF KGCW KLJB  ourquadcities.com  Davenport, IA - Rock Island / Moline   \n",
       "1       KTVX KUCW      good4utah.com                        Salt Lake City   \n",
       "2            WVNS         wvnstv.com                   Bluefield / Beckley   \n",
       "\n",
       "  state broadcaster      source             collection_date  \n",
       "0    IL     Nexstar  nexstar.tv  2018-08-02 14:55:24.612585  \n",
       "1    UT     Nexstar  nexstar.tv  2018-08-02 14:55:24.612585  \n",
       "2    WV     Nexstar  nexstar.tv  2018-08-02 14:55:24.612585  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "#### What do the columns mean?\n",
       "| Column Name | Description | N Unique Values |\n",
       "| --- | --- | --- |\n",
       "| `station` | The name of the TV station IE (\"KRIV\"). If anyone knows the origin of this naming convention, I would love to know! | 100 |\n",
       "| `website` | The website of the media outlet exactly as we found it online. | 98 |\n",
       "| `city` | The name of the city that the TV station broadcasts from. | 97 |\n",
       "| `state` | The two letter state abbreviation of the media outlet. | 39 |\n",
       "| `broadcaster` | The corporate owner of the station. | 1 |\n",
       "| `source` | Where was this record scraped from? | 1 |\n",
       "| `collection_date` | when was this record collected? | 1 |\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "[Top of Data Sheet](#datasheet)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "## <a name='hearst'>hearst.tsv</a>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "An intermediate file of news outlets owned by Hearst scraped from their website"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Read the raw file from this URL: \n",
       " `TODO`\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "See the code used to make this dataset: \n",
       " `TODO`\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "#### What Does the Data Look Like?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Sample of `../data/hearst.tsv` (N = 33)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>facebook</th>\n",
       "      <th>network</th>\n",
       "      <th>state</th>\n",
       "      <th>station</th>\n",
       "      <th>twitter</th>\n",
       "      <th>website</th>\n",
       "      <th>broadcaster</th>\n",
       "      <th>source</th>\n",
       "      <th>collection_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Monterey-Salinas</td>\n",
       "      <td>https://www.facebook.com/ksbw8?fref=ts</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CA</td>\n",
       "      <td>KSBW-TV</td>\n",
       "      <td>https://twitter.com/ksbw</td>\n",
       "      <td>http://www.ksbw.com/</td>\n",
       "      <td>Hearst</td>\n",
       "      <td>hearst.com</td>\n",
       "      <td>2018-08-02 14:55:24.612585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Portland-Auburn</td>\n",
       "      <td>https://www.facebook.com/wmtwtv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ME</td>\n",
       "      <td>WMTW-TV</td>\n",
       "      <td>https://twitter.com/WMTWTV</td>\n",
       "      <td>http://www.wmtw.com/</td>\n",
       "      <td>Hearst</td>\n",
       "      <td>hearst.com</td>\n",
       "      <td>2018-08-02 14:55:24.612585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Burlington  VT/Plattsburgh</td>\n",
       "      <td>https://www.facebook.com/5WPTZ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NY</td>\n",
       "      <td>WPTZ-TV/WNNE-TV</td>\n",
       "      <td>https://twitter.com/mynbc5</td>\n",
       "      <td>http://www.wptz.com/</td>\n",
       "      <td>Hearst</td>\n",
       "      <td>hearst.com</td>\n",
       "      <td>2018-08-02 14:55:24.612585</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         city                                facebook  \\\n",
       "0            Monterey-Salinas  https://www.facebook.com/ksbw8?fref=ts   \n",
       "1             Portland-Auburn         https://www.facebook.com/wmtwtv   \n",
       "2  Burlington  VT/Plattsburgh          https://www.facebook.com/5WPTZ   \n",
       "\n",
       "   network state           station                     twitter  \\\n",
       "0      NaN    CA           KSBW-TV    https://twitter.com/ksbw   \n",
       "1      NaN    ME           WMTW-TV  https://twitter.com/WMTWTV   \n",
       "2      NaN    NY  WPTZ-TV/WNNE-TV   https://twitter.com/mynbc5   \n",
       "\n",
       "                website broadcaster      source             collection_date  \n",
       "0  http://www.ksbw.com/      Hearst  hearst.com  2018-08-02 14:55:24.612585  \n",
       "1  http://www.wmtw.com/      Hearst  hearst.com  2018-08-02 14:55:24.612585  \n",
       "2  http://www.wptz.com/      Hearst  hearst.com  2018-08-02 14:55:24.612585  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "#### What do the columns mean?\n",
       "| Column Name | Description | N Unique Values |\n",
       "| --- | --- | --- |\n",
       "| `city` | The name of the city that the TV station broadcasts from. | 27 |\n",
       "| `facebook` | The URL to the media outlet's Facebook presence. | 33 |\n",
       "| `network` | The franchise or brand name that the station belongs to IE Fox | 1 |\n",
       "| `state` | The two letter state abbreviation of the media outlet. | 23 |\n",
       "| `station` | The name of the TV station IE (\"KRIV\"). If anyone knows the origin of this naming convention, I would love to know! | 33 |\n",
       "| `twitter` | The URL to the Twitter screen name of the news outlet. | 30 |\n",
       "| `website` | The website of the media outlet exactly as we found it online. | 33 |\n",
       "| `broadcaster` | The corporate owner of the station. | 1 |\n",
       "| `source` | Where was this record scraped from? | 1 |\n",
       "| `collection_date` | when was this record collected? | 1 |\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "[Top of Data Sheet](#datasheet)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "## <a name='tribune'>tribune.tsv</a>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "An intermediate file of news outlets owned by Tribune scraped from their website."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Read the raw file from this URL: \n",
       " `TODO`\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "See the code used to make this dataset: \n",
       " `TODO`\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "#### What Does the Data Look Like?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Sample of `../data/tribune.tsv` (N = 47)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>facebook</th>\n",
       "      <th>network</th>\n",
       "      <th>station</th>\n",
       "      <th>twitter</th>\n",
       "      <th>website</th>\n",
       "      <th>youtube</th>\n",
       "      <th>broadcaster</th>\n",
       "      <th>source</th>\n",
       "      <th>state</th>\n",
       "      <th>collection_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>South Florida</td>\n",
       "      <td>http://www.facebook.com/SFLCW</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WSFL</td>\n",
       "      <td>https://twitter.com/SFLCW</td>\n",
       "      <td>http://sfltv.net/</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tribune</td>\n",
       "      <td>tribunemedia.com</td>\n",
       "      <td>FL</td>\n",
       "      <td>2018-08-02 14:55:24.612585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Indianapolis</td>\n",
       "      <td>https://www.facebook.com/CBS4Indy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WTTV</td>\n",
       "      <td>https://twitter.com/cbs4indy</td>\n",
       "      <td>http://cbs4indy.com/</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tribune</td>\n",
       "      <td>tribunemedia.com</td>\n",
       "      <td>IN</td>\n",
       "      <td>2018-08-02 14:55:24.612585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dallas</td>\n",
       "      <td>https://www.facebook.com/NightcapNews</td>\n",
       "      <td>NaN</td>\n",
       "      <td>KDAF</td>\n",
       "      <td>https://twitter.com/NewsFixDFW</td>\n",
       "      <td>http://cw33.com/</td>\n",
       "      <td>http://www.youtube.com/user/kdaf</td>\n",
       "      <td>Tribune</td>\n",
       "      <td>tribunemedia.com</td>\n",
       "      <td>TX</td>\n",
       "      <td>2018-08-02 14:55:24.612585</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            city                               facebook  network station  \\\n",
       "0  South Florida          http://www.facebook.com/SFLCW      NaN    WSFL   \n",
       "1   Indianapolis      https://www.facebook.com/CBS4Indy      NaN    WTTV   \n",
       "2         Dallas  https://www.facebook.com/NightcapNews      NaN    KDAF   \n",
       "\n",
       "                          twitter               website  \\\n",
       "0       https://twitter.com/SFLCW     http://sfltv.net/   \n",
       "1    https://twitter.com/cbs4indy  http://cbs4indy.com/   \n",
       "2  https://twitter.com/NewsFixDFW      http://cw33.com/   \n",
       "\n",
       "                            youtube broadcaster            source state  \\\n",
       "0                               NaN     Tribune  tribunemedia.com    FL   \n",
       "1                               NaN     Tribune  tribunemedia.com    IN   \n",
       "2  http://www.youtube.com/user/kdaf     Tribune  tribunemedia.com    TX   \n",
       "\n",
       "              collection_date  \n",
       "0  2018-08-02 14:55:24.612585  \n",
       "1  2018-08-02 14:55:24.612585  \n",
       "2  2018-08-02 14:55:24.612585  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "#### What do the columns mean?\n",
       "| Column Name | Description | N Unique Values |\n",
       "| --- | --- | --- |\n",
       "| `city` | The name of the city that the TV station broadcasts from. | 36 |\n",
       "| `facebook` | The URL to the media outlet's Facebook presence. | 46 |\n",
       "| `network` | The franchise or brand name that the station belongs to IE Fox | 1 |\n",
       "| `station` | The name of the TV station IE (\"KRIV\"). If anyone knows the origin of this naming convention, I would love to know! | 46 |\n",
       "| `twitter` | The URL to the Twitter screen name of the news outlet. | 43 |\n",
       "| `website` | The website of the media outlet exactly as we found it online. | 47 |\n",
       "| `youtube` | The URL to the media outlet's YouTube presence. | 30 |\n",
       "| `broadcaster` | The corporate owner of the station. | 1 |\n",
       "| `source` | Where was this record scraped from? | 1 |\n",
       "| `state` | The two letter state abbreviation of the media outlet. | 27 |\n",
       "| `collection_date` | when was this record collected? | 1 |\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "[Top of Data Sheet](#datasheet)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "## <a name='station_index'>station_index.tsv</a>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "An intermediate file of TV stations compiled on stationindex.com. The website is scraped according to the market (reigon), and again according to the owner. The two scraped datasets are merged and duplicates are dropped. When dropping duplicates, precedence is given to the entry scraped owners."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Read the raw file from this URL: \n",
       " `TODO`\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "See the code used to make this dataset: \n",
       " `TODO`\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "#### What Does the Data Look Like?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Sample of `../data/station_index.tsv` (N = 1867)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>id</th>\n",
       "      <th>owner</th>\n",
       "      <th>state</th>\n",
       "      <th>station_info</th>\n",
       "      <th>station_name</th>\n",
       "      <th>subchannels</th>\n",
       "      <th>website</th>\n",
       "      <th>source</th>\n",
       "      <th>collection_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Houston</td>\n",
       "      <td>\"FOX 26\"</td>\n",
       "      <td>Fox Television Stations</td>\n",
       "      <td>TX</td>\n",
       "      <td>Digital Full-Power - 1000 kW</td>\n",
       "      <td>KRIV</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://www.fox26houston.com/</td>\n",
       "      <td>stationindex</td>\n",
       "      <td>2018-08-02 14:55:24.612585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Boise</td>\n",
       "      <td>\"Telemundo Boise\"</td>\n",
       "      <td>Boise Telecasters</td>\n",
       "      <td>ID</td>\n",
       "      <td>Digital Full-Power - 35 kW</td>\n",
       "      <td>KKJB</td>\n",
       "      <td>39.1 Telemundo, 39.2 Cozi TV, 39.3 Antenna TV...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>stationindex</td>\n",
       "      <td>2018-08-02 14:55:24.612585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Phoenix</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Daystar</td>\n",
       "      <td>AZ</td>\n",
       "      <td>Low-Power - 150 kW</td>\n",
       "      <td>KDPH-LP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>stationindex</td>\n",
       "      <td>2018-08-02 14:55:24.612585</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       city                  id                     owner state  \\\n",
       "0   Houston            \"FOX 26\"   Fox Television Stations    TX   \n",
       "1     Boise   \"Telemundo Boise\"         Boise Telecasters    ID   \n",
       "2   Phoenix                 NaN                   Daystar    AZ   \n",
       "\n",
       "                    station_info station_name  \\\n",
       "0   Digital Full-Power - 1000 kW         KRIV   \n",
       "1     Digital Full-Power - 35 kW         KKJB   \n",
       "2             Low-Power - 150 kW      KDPH-LP   \n",
       "\n",
       "                                         subchannels  \\\n",
       "0                                                NaN   \n",
       "1   39.1 Telemundo, 39.2 Cozi TV, 39.3 Antenna TV...   \n",
       "2                                                NaN   \n",
       "\n",
       "                        website        source             collection_date  \n",
       "0  http://www.fox26houston.com/  stationindex  2018-08-02 14:55:24.612585  \n",
       "1                           NaN  stationindex  2018-08-02 14:55:24.612585  \n",
       "2                           NaN  stationindex  2018-08-02 14:55:24.612585  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "#### What do the columns mean?\n",
       "| Column Name | Description | N Unique Values |\n",
       "| --- | --- | --- |\n",
       "| `city` | The name of the city that the TV station broadcasts from. | 676 |\n",
       "| `id` | The human-recognizable name for the TV station. | 699 |\n",
       "| `owner` | The corporate owner of the station. | 641 |\n",
       "| `state` | The two letter state abbreviation of the media outlet. | 56 |\n",
       "| `station_info` | Typically related to the frequency of the transmission | 765 |\n",
       "| `station_name` | The name of the TV station IE (\"KRIV\"). If anyone knows the origin of this naming convention, I would love to know! | 1866 |\n",
       "| `subchannels` | Alternative names for the TV station | 626 |\n",
       "| `website` | The website of the media outlet exactly as we found it online. | 1172 |\n",
       "| `source` | Where was this record scraped from? | 1 |\n",
       "| `collection_date` | when was this record collected? | 1 |\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "[Top of Data Sheet](#datasheet)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "## <a name='usnpl'>usnpl.tsv</a>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "An intermediate file of News papers, magazines and college papers compiled by usnpl.com. The website is scraped by visiting state-specific pages using requests and BeautifulSoup, websites and social media are collected wherever possible."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Read the raw file from this URL: \n",
       " `TODO`\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "See the code used to make this dataset: \n",
       " `TODO`\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "#### What Does the Data Look Like?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Sample of `../data/usnpl.tsv` (N = 6221)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Facebook</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Medium</th>\n",
       "      <th>Name</th>\n",
       "      <th>Twitter_Name</th>\n",
       "      <th>Website</th>\n",
       "      <th>Youtube</th>\n",
       "      <th>source</th>\n",
       "      <th>collection_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.facebook.com/MissionTimesCourier</td>\n",
       "      <td>CA</td>\n",
       "      <td>Newspapers</td>\n",
       "      <td>Mission Times Courier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://www.missiontimescourier.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>usnpl.com</td>\n",
       "      <td>2018-08-02 14:55:24.612585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.facebook.com/adelantevalle</td>\n",
       "      <td>CA</td>\n",
       "      <td>Newspapers</td>\n",
       "      <td>Adelante Valle</td>\n",
       "      <td>IVPNews</td>\n",
       "      <td>http://www.ivpressonline.com/adelantevalle</td>\n",
       "      <td>http://www.youtube.com/user/ivpressonline</td>\n",
       "      <td>usnpl.com</td>\n",
       "      <td>2018-08-02 14:55:24.612585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.facebook.com/calmarcourier</td>\n",
       "      <td>IA</td>\n",
       "      <td>Newspapers</td>\n",
       "      <td>Calmar Courier</td>\n",
       "      <td>calmarcourier</td>\n",
       "      <td>http://calmarcourier.com</td>\n",
       "      <td>https://www.youtube.com/channel/UCVTvRL0P_eaIU...</td>\n",
       "      <td>usnpl.com</td>\n",
       "      <td>2018-08-02 14:55:24.612585</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Facebook Geography      Medium  \\\n",
       "0  https://www.facebook.com/MissionTimesCourier        CA  Newspapers   \n",
       "1        https://www.facebook.com/adelantevalle        CA  Newspapers   \n",
       "2        https://www.facebook.com/calmarcourier        IA  Newspapers   \n",
       "\n",
       "                    Name   Twitter_Name  \\\n",
       "0  Mission Times Courier            NaN   \n",
       "1         Adelante Valle        IVPNews   \n",
       "2         Calmar Courier  calmarcourier   \n",
       "\n",
       "                                      Website  \\\n",
       "0          http://www.missiontimescourier.com   \n",
       "1  http://www.ivpressonline.com/adelantevalle   \n",
       "2                    http://calmarcourier.com   \n",
       "\n",
       "                                             Youtube     source  \\\n",
       "0                                                NaN  usnpl.com   \n",
       "1          http://www.youtube.com/user/ivpressonline  usnpl.com   \n",
       "2  https://www.youtube.com/channel/UCVTvRL0P_eaIU...  usnpl.com   \n",
       "\n",
       "              collection_date  \n",
       "0  2018-08-02 14:55:24.612585  \n",
       "1  2018-08-02 14:55:24.612585  \n",
       "2  2018-08-02 14:55:24.612585  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "#### What do the columns mean?\n",
       "| Column Name | Description | N Unique Values |\n",
       "| --- | --- | --- |\n",
       "| `Facebook` | The URL to the media outlet's Facebook presence. | 5100 |\n",
       "| `Geography` | The two letter state abbreviation of the media outlet. | 51 |\n",
       "| `Medium` | Whether the news outlet us a newspaper (includes online), magazine, or college newspaper. | 3 |\n",
       "| `Name` | The name of the TV station IE (\"KRIV\"). If anyone knows the origin of this naming convention, I would love to know! | 5765 |\n",
       "| `Twitter_Name` | The Twitter screen name of the news outlet. | 3643 |\n",
       "| `Website` | The website of the media outlet exactly as we found it online. | 6080 |\n",
       "| `Youtube` | The URL to the media outlet's YouTube presence. | 2226 |\n",
       "| `source` | Where was this record scraped from? | 1 |\n",
       "| `collection_date` | when was this record collected? | 1 |\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "[Top of Data Sheet](#datasheet)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "## <a name='local_news_dataset_2018'>local_news_dataset_2018.tsv</a>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "The intermediaries are merged (using this script), and preprocessed resulting in this file"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Read the raw file from this URL: \n",
       " `TODO`\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "See the code used to make this dataset: \n",
       " `TODO`\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "#### What Does the Data Look Like?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Sample of `../data/local_news_dataset_2018.csv` (N = 7632)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>state</th>\n",
       "      <th>website</th>\n",
       "      <th>domain</th>\n",
       "      <th>twitter</th>\n",
       "      <th>youtube</th>\n",
       "      <th>facebook</th>\n",
       "      <th>owner</th>\n",
       "      <th>medium</th>\n",
       "      <th>source</th>\n",
       "      <th>collection_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KTEJ</td>\n",
       "      <td>AR</td>\n",
       "      <td>http://www.aetn.org/</td>\n",
       "      <td>aetn.org</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Arkansas Educational Television</td>\n",
       "      <td>TV station</td>\n",
       "      <td>stationindex</td>\n",
       "      <td>2018-08-02 14:55:24.612585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Vienna Connection</td>\n",
       "      <td>VA</td>\n",
       "      <td>http://www.viennaconnection.com</td>\n",
       "      <td>viennaconnection.com</td>\n",
       "      <td>viennaconnect</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.facebook.com/ConnectionNewspapers</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Newspapers</td>\n",
       "      <td>usnpl.com</td>\n",
       "      <td>2018-08-02 14:55:24.612585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Salem News</td>\n",
       "      <td>OH</td>\n",
       "      <td>http://www.salemnews.net</td>\n",
       "      <td>salemnews.net</td>\n",
       "      <td>SalemNewsOH</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.facebook.com/SalemNews</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Newspapers</td>\n",
       "      <td>usnpl.com</td>\n",
       "      <td>2018-08-02 14:55:24.612585</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                name state                          website  \\\n",
       "0               KTEJ    AR             http://www.aetn.org/   \n",
       "1  Vienna Connection    VA  http://www.viennaconnection.com   \n",
       "2         Salem News    OH         http://www.salemnews.net   \n",
       "\n",
       "                 domain        twitter youtube  \\\n",
       "0              aetn.org            NaN     NaN   \n",
       "1  viennaconnection.com  viennaconnect     NaN   \n",
       "2         salemnews.net    SalemNewsOH     NaN   \n",
       "\n",
       "                                        facebook  \\\n",
       "0                                            NaN   \n",
       "1  https://www.facebook.com/ConnectionNewspapers   \n",
       "2             https://www.facebook.com/SalemNews   \n",
       "\n",
       "                             owner      medium        source  \\\n",
       "0  Arkansas Educational Television  TV station  stationindex   \n",
       "1                              NaN  Newspapers     usnpl.com   \n",
       "2                              NaN  Newspapers     usnpl.com   \n",
       "\n",
       "              collection_date  \n",
       "0  2018-08-02 14:55:24.612585  \n",
       "1  2018-08-02 14:55:24.612585  \n",
       "2  2018-08-02 14:55:24.612585  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "#### What do the columns mean?\n",
       "| Column Name | Description | N Unique Values |\n",
       "| --- | --- | --- |\n",
       "| `name` | The name of the TV station IE (\"KRIV\"). If anyone knows the origin of this naming convention, I would love to know! | 7096 |\n",
       "| `state` | The two letter state abbreviation of the media outlet. | 55 |\n",
       "| `website` | The website of the media outlet exactly as we found it online. | 7375 |\n",
       "| `domain` | The domain that houses the media outlet. It is standardized (no \"www\" or \"http://\"). Sometimes multiple media outlets direct to the same domain (but seprate sub-domain). | 6495 |\n",
       "| `twitter` | The Twitter screen name of the news outlet. | 3675 |\n",
       "| `youtube` | The URL to the media outlet's YouTube presence. | 2240 |\n",
       "| `facebook` | The URL to the media outlet's Facebook presence. | 5136 |\n",
       "| `owner` | The corporate owner of the station. | 443 |\n",
       "| `medium` | Whether the news outlet us a newspaper (includes online), magazine or a TV station | 4 |\n",
       "| `source` | Where was this record scraped from? | 8 |\n",
       "| `collection_date` | when was this record collected? | 2 |\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "#### Breakdown of mediums in the Local News Dataset"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>medium</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Newspapers</th>\n",
       "      <td>5380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TV station</th>\n",
       "      <td>1461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>College Newspapers</th>\n",
       "      <td>480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Magazines</th>\n",
       "      <td>311</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    medium\n",
       "Newspapers            5380\n",
       "TV station            1461\n",
       "College Newspapers     480\n",
       "Magazines              311"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "#### Breakdown of data sources in the Local News Dataset"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>usnpl.com</th>\n",
       "      <td>6163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stationindex</th>\n",
       "      <td>1050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sbgi.net</th>\n",
       "      <td>217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nexstar.tv</th>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tribunemedia.com</th>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hearst.com</th>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>meridith.com</th>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User Input</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  source\n",
       "usnpl.com           6163\n",
       "stationindex        1050\n",
       "sbgi.net             217\n",
       "nexstar.tv            98\n",
       "tribunemedia.com      47\n",
       "hearst.com            33\n",
       "meridith.com          15\n",
       "User Input             9"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "`User Input` are custom additions added from the contents of [this JSON file](#TODO) in [this section](#TODO) of the `merge.py"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Below is an interactive [Plot.ly](https://plot.ly) chloropleth map of state-level representation in this dataset. Scroll over each state to get a list of the top mediums and owners."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~leonyin/58.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from runtimestamp.runtimestamp import runtimestamp # for reproducibility\n",
    "from docs.build_docs import *                      # auto-generates docs\n",
    "runtimestamp('Leon')\n",
    "generate_docs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Using the Dataset <a name='use'></a>\n",
    "If you want to use this dataset to link web domains to states, there are a few steps you'll need to take:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6493"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/state.tsv\", sep='\\t')\n",
    "df_local_website = df[(~df.domain.isnull()) &\n",
    "                      (df.domain != 'facebook.com')].drop_duplicates(subset=['domain'])\n",
    "len(df_local_website)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We do this because some entries don't have websites and some websites are just Facebook pages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>state</th>\n",
       "      <th>website</th>\n",
       "      <th>domain</th>\n",
       "      <th>twitter</th>\n",
       "      <th>youtube</th>\n",
       "      <th>facebook</th>\n",
       "      <th>owner</th>\n",
       "      <th>medium</th>\n",
       "      <th>source</th>\n",
       "      <th>collection_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>468</th>\n",
       "      <td>WIPB</td>\n",
       "      <td>IN</td>\n",
       "      <td>http://www.bsu.edu/wipb/</td>\n",
       "      <td>bsu.edu</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ball State University</td>\n",
       "      <td>TV station</td>\n",
       "      <td>stationindex</td>\n",
       "      <td>2018-08-02 14:55:24.612585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6431</th>\n",
       "      <td>Nugget Newspaper</td>\n",
       "      <td>OR</td>\n",
       "      <td>http://www.nuggetnews.com</td>\n",
       "      <td>nuggetnews.com</td>\n",
       "      <td>Nuggetnewspaper</td>\n",
       "      <td>https://www.youtube.com/user/sistersnuggetnews</td>\n",
       "      <td>https://www.facebook.com/NuggetNews</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Newspapers</td>\n",
       "      <td>usnpl.com</td>\n",
       "      <td>2018-08-02 14:55:24.612585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3122</th>\n",
       "      <td>Hamburg Reporter</td>\n",
       "      <td>IA</td>\n",
       "      <td>http://www.hamburgreporter.com</td>\n",
       "      <td>hamburgreporter.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.facebook.com/pages/Hamburg-Reporte...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Newspapers</td>\n",
       "      <td>usnpl.com</td>\n",
       "      <td>2018-08-02 14:55:24.612585</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  name state                         website  \\\n",
       "468               WIPB    IN        http://www.bsu.edu/wipb/   \n",
       "6431  Nugget Newspaper    OR       http://www.nuggetnews.com   \n",
       "3122  Hamburg Reporter    IA  http://www.hamburgreporter.com   \n",
       "\n",
       "                   domain          twitter  \\\n",
       "468               bsu.edu              NaN   \n",
       "6431       nuggetnews.com  Nuggetnewspaper   \n",
       "3122  hamburgreporter.com              NaN   \n",
       "\n",
       "                                             youtube  \\\n",
       "468                                              NaN   \n",
       "6431  https://www.youtube.com/user/sistersnuggetnews   \n",
       "3122                                             NaN   \n",
       "\n",
       "                                               facebook  \\\n",
       "468                                                 NaN   \n",
       "6431                https://www.facebook.com/NuggetNews   \n",
       "3122  https://www.facebook.com/pages/Hamburg-Reporte...   \n",
       "\n",
       "                      owner      medium        source  \\\n",
       "468   Ball State University  TV station  stationindex   \n",
       "6431                    NaN  Newspapers     usnpl.com   \n",
       "3122                    NaN  Newspapers     usnpl.com   \n",
       "\n",
       "                 collection_date  \n",
       "468   2018-08-02 14:55:24.612585  \n",
       "6431  2018-08-02 14:55:24.612585  \n",
       "3122  2018-08-02 14:55:24.612585  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_local_website.sample(3, random_state=303)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm planning on writing some tutorials for using the data!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Data Sheet <a name='datasheet'></a>\n",
    "In the spirit of transparency and good documentation, I am going to answer some questions for datasets proposed in the recent paper [Datasheets for Datasets](https://arxiv.org/abs/1803.09010) by \n",
    "Datasheets for Datasets Timnit Gebru, Jamie Morgenstern, Briana Vecchione, Jennifer Wortman Vaughan, Hanna Wallach, Hal Daume III, Kate Crawford.\n",
    "\n",
    "### Motivation for Dataset Creation\n",
    "*Why was the dataset created? (e.g., were there specific\n",
    "tasks in mind, or a specific gap that needed to be filled?)*<br>\n",
    "This Dataset was created to study the role of state-level local news on Twitter.<br>\n",
    "We wanted to find users who follow both local news outlets and members of congress.<br>\n",
    "\n",
    "*What (other) tasks could the dataset be used for? Are\n",
    "there obvious tasks for which it should not be used?*<br>\n",
    "The dataset can be used to query other social media platforms for local news outlet's social feeds.<br>\n",
    "It can also serve as a list of state-level domains for link analysis, as it was used in an uncoming report on the Internet Research Agency's use of links on Twitter.<br>\n",
    "I am hoping that this dataset might be of interest to applicants for the [Social Science One and Facebook RFP](https://socialscience.one/our-facebook-partnership), and others curious about local news.\n",
    "\n",
    "*Has the dataset been used for any tasks already? If so,\n",
    "where are the results so others can compare (e.g., links to\n",
    "published papers)?*<br>\n",
    "A study of IRA Twitter accounts sharing national, local, and junk news articles.\n",
    "\n",
    "*Who funded the creation of the dataset? If there is an\n",
    "associated grant, provide the grant number.*<br>\n",
    "This dataset was created by Leon Yin and the SMaPP Lab at NYU.\n",
    "We have recieved funding from the NSF, the Knight Foundation, the Bill & Melinda Gates Foundation, the Hewlett Foundation and the Rita Allen Foundation. For more information, please visit our [website](https://wp.nyu.edu/smapp/).\n",
    "\n",
    "### Dataset Composition\n",
    "*What are the instances? (that is, examples; e.g., documents,\n",
    "images, people, countries) Are there multiple types\n",
    "of instances? (e.g., movies, users, ratings; people, interactions\n",
    "between them; nodes, edges)*<br>\n",
    "Each instance is a local news outlet.\n",
    "\n",
    "\n",
    "*Are relationships between instances made explicit in\n",
    "the data (e.g., social network links, user/movie ratings, etc.)?\n",
    "How many instances of each type are there?*<br>\n",
    "We have relational links in this data, but that is up to you to make those connections. For counts, please refer to the spec sheet above.\n",
    "\n",
    "*What data does each instance consist of? Raw data\n",
    "(e.g., unprocessed text or images)? Features/attributes?*<br>\n",
    "Each instance is a scraped entity from a website. There are no images involved. The metadata fields regarding state, website, and social accounts are scraped from raw HTML.\n",
    "\n",
    "\n",
    "*Is there a label/target associated with instances? If the instances are related to people, are subpopulations identified\n",
    "(e.g., by age, gender, etc.) and what is their distribution?*<br>\n",
    "This is not a traditional supervised machine learning dataset.\n",
    "\n",
    "*Is everything included or does the data rely on external\n",
    "resources? (e.g., websites, tweets, datasets) If external\n",
    "resources, a) are there guarantees that they will exist, and\n",
    "remain constant, over time; b) is there an official archival\n",
    "version.*<br>\n",
    "The data relies of external sources! There are abolutely no guarentees that data to Twitter, Youtube, Facebook, the source websites (where data is scraped), or the destination websites (homepages for news outlets). \n",
    "\n",
    "Currently there are open source libraries -- like [TweePy](http://www.tweepy.org/), to query Twitter, and my collegue Megan Brown and I are about to release a Python wrapper for the Youtube Data API library.\n",
    "\n",
    "*Are there licenses, fees or rights associated with\n",
    "any of the data?*<br>\n",
    "This dataset is free to use. We're copying terms of use from [Propublica](https://www.propublica.org/datastore/terms):\n",
    "```\n",
    "In general, you may use Leon Yin and the SMaPP Lab at NYU's data under the following terms. However, there may be different terms included for some data sets. It is your responsibility to read carefully the specific terms included with the data you download or purchase from our website.\n",
    "\n",
    "You cant republish the raw data in its entirety, or otherwise distribute the data (in whole or in part) on a stand-alone basis.\n",
    "You cant change the data except to update or correct it.\n",
    "You cant charge people money to look at the data, or sell advertising specifically against it.\n",
    "You cant sub-license or resell the data to others.\n",
    "If you use the data for publication, you must cite Leon Yin and the SMaPP Lab at NYU. \n",
    "We do not guarantee the accuracy or completeness of the data. You acknowledge that the data may contain errors and omissions. \n",
    "We are not obligated to update the data, but in the event we do, you are solely responsible for checking our site for any updates.\n",
    "You will indemnify, hold harmless, and defend ProPublica from and against any claims arising out of your use of the data.\n",
    "```\n",
    "\n",
    "### Data Collection Process\n",
    "*How was the data collected? (e.g., hardware apparatus/sensor,\n",
    "manual human curation, software program,\n",
    "software interface/API; how were these constructs/measures/methods\n",
    "validated?)*<br>\n",
    "The data was collected using 4 CPUs on the NYU HPC Prince Cluster. It was written using [custom code](TODO) that utilizes the requests, beautifulsoup, and Pandas Python libraries. For this reason no APIs are used to collect this data. Data was quality checked by exploring data in Jupyter Noteooks. It was compared to lists curated by [AbilityPR](https://www.agilitypr.com/resources/top-media-outlets/) of the top 10 newspapers by state.\n",
    "\n",
    "*Who was involved in the data collection process?*<br>\n",
    "This dataset was collected by Leon Yin.\n",
    "\n",
    "*Over what time-frame was the data collected?* <br>\n",
    "The `process_datetime` columns capture when datasets are collected. Initial development for this project began in April 2018.\n",
    "\n",
    "*How was the data associated with each instance acquired?*<br>\n",
    "Data is directly scraped from HTML, there is no inferred data. There is no information how the sources curate their websites-- especially TVstationindex.com and USNPL.com.\n",
    "\n",
    "*Does the dataset contain all possible instances?* <br>\n",
    "Ths is not a sample, but the best attempt at creating a comprehensive list.\n",
    "\n",
    "*Is there information missing from the dataset and why?* <br>\n",
    "News Outlets not listed in the websites we scrape, or the custom additions JSON are not included. We'll make attempt to take requests for additions and ammendments on GitHub with the intention of creating a website with a submission forum.\n",
    "\n",
    "*Are there any known errors, sources of noise, or redundancies\n",
    "in the data?*\n",
    "There are possible redundencies of news outlets occuring across the websites scraped. We have measures to drop duplicates, but if we missed any please submit an error in GitHub.\n",
    "\n",
    "### Data Preprocessing\n",
    "*What preprocessing/cleaning was done?* <br>\n",
    "Twitter Screen Names are extracted from URLs, states are parsed from raw HTML that usually contains a city name, there is no aggregation or engineered features.\n",
    "\n",
    "*Was the raw data saved in addition to the preprocessed/cleaned\n",
    "data?* <br>\n",
    "The raw HTML for each site is not provided (so changes in website UI's) will crash future collection. There are no warranties for this. However the intermediate files are saved, and thoroughly documented in the [tech specs](#specs) above.\n",
    "\n",
    "*Is the preprocessing software available?* <br>\n",
    "The dataset is a standard CSV, so any relevant open source software can be used.\n",
    "\n",
    "*Does this dataset collection/processing procedure\n",
    "achieve the motivation for creating the dataset stated\n",
    "in the first section of this datasheet?* <br>\n",
    "The addition of Twitter Screen names makes it possible to use this data for Twitter research. The inclusion of additional fields like website, other social media platforms (Facebook, Youtube) allows for additional applications\n",
    "\n",
    "\n",
    "### Dataset Distribution\n",
    "*How is the dataset distributed? (e.g., website, API, etc.;\n",
    "does the data have a DOI; is it archived redundantly?)* <br>\n",
    "The dataset is being hosted on GitHub at the moment. It does not have a DOI (if you have suggestions on how to get one please reach out!). There are plans to migrate the dataset to its own website.\n",
    "\n",
    "*When will the dataset be released/first distributed?*\n",
    "August 2018.\n",
    "\n",
    "*What license (if any) is it distributed under?*\n",
    "MIT\n",
    "\n",
    "*Are there any fees or access/export restrictions?*\n",
    "Not while it is on GitHub, but if its migrated elsewhere that's possible.\n",
    "\n",
    "### Dataset Maintenance\n",
    "*Who is supporting/hosting/maintaining the dataset?* <br>\n",
    "The dataset is currently solely maintained by Leon Yin. This seems unsustainable, so if this project sparks an interest with you please reach out to me here: `data-smapp_lab at nyu dot edu`\n",
    "\n",
    "*Will the dataset be updated? How often and by whom?\n",
    "How will updates/revisions be documented and communicated\n",
    "(e.g., mailing list, GitHub)? Is there an erratum?*<br>\n",
    "The dataset can be updated locally by running the scripts in this repo. Ammendments to the hosted dataset will contain a separate filepath and URL, and be documented in the README.\n",
    "\n",
    "\n",
    "*If the dataset becomes obsolete how will this be communicated?*<br>\n",
    "If the dataset becomes obsolete, we'll make this clear in the README in the GitHub repository (or whereever it is being hosted).\n",
    "\n",
    "*Is there a repository to link to any/all papers/systems\n",
    "that use this dataset?*<br>\n",
    "There aren't any publications that use this dataset that are published. We'll keep a list on the README or the website.\n",
    "\n",
    "*If others want to extend/augment/build on this dataset,\n",
    "is there a mechanism for them to do so?* <br>\n",
    "Modifications can be made by adding records to the ammendments [JSON](todo).\n",
    "\n",
    "### Legal & Ethical Considerations\n",
    "*If the dataset relates to people (e.g., their attributes) or\n",
    "was generated by people, were they informed about the\n",
    "data collection?* <br>\n",
    "This dataset has no people-level information. However we don't know anything about the people who generated the webpages that this dataset is built on.\n",
    "\n",
    "*Does the dataset contain information that might be considered\n",
    "sensitive or confidential?* <br>\n",
    "To my knowledge there is no personally identifiable information in this dataset.\n",
    "\n",
    "*Does the dataset contain information that might be considered\n",
    "inappropriate or offensive?* <br>\n",
    "Some might call some of the outlets \"Fake News\" ;)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
